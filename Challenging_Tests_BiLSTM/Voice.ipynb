{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8f8ac2",
   "metadata": {},
   "source": [
    "### Konstantina Andronikou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a2d4d",
   "metadata": {},
   "source": [
    "## This Notebook implements a comparison between Active and Passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8173efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models.pretrained import load_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61058920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "import logging\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4506b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457d569",
   "metadata": {},
   "source": [
    "## Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a08189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing warnings\n",
    "logging.getLogger('allennlp.common.params').disabled = True \n",
    "logging.getLogger('allennlp.nn.initializers').disabled = True \n",
    "logging.getLogger('allennlp.modules.token_embedders.embedding').disabled = True \n",
    "logging.getLogger('urllib3.connectionpool').disabled = True \n",
    "logging.getLogger('allennlp.common.plugins').disabled = True \n",
    "logging.getLogger('allennlp.common.model_card').disabled = True \n",
    "logging.getLogger('allennlp.models.archival').disabled = True \n",
    "logging.getLogger('allennlp.data.vocabulary').disabled = True \n",
    "logging.getLogger('cached_path').disabled = True\n",
    "\n",
    "srl_predictor = load_predictor('structured-prediction-srl')\n",
    "output = srl_predictor.predict(\"Someone drove Mary to school\")\n",
    "#output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f689a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_srl(data):\n",
    "    \n",
    "    pred = []\n",
    "    for d in data:\n",
    "        pred.append(srl_predictor.predict(d))\n",
    "    return pred\n",
    "\n",
    "predict_and_conf = PredictorWrapper.wrap_predict(predict_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff2c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\"Someone drove Mary to school\"]\n",
    "pred = predict_and_conf(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ec918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_srl(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    return pred['verbs'][0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616f0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg(pred, arg_target='ARG0'):\n",
    "    predicate_arguments = pred['verbs'][0]\n",
    "    #print(predicate_arguments)\n",
    "    words = pred['words']\n",
    "    tags = predicate_arguments['tags']\n",
    "    \n",
    "    arg_list = []\n",
    "    for t, w in zip(tags, words):\n",
    "        arg = t\n",
    "        if '-' in t:\n",
    "            arg = t.split('-')[1]\n",
    "        if arg == arg_target:\n",
    "            arg_list.append(w)\n",
    "    arg_set = set(arg_list)\n",
    "    return arg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f5e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_srl(x, pred, conf, label=None, meta=None):\n",
    "    results = []\n",
    "    predicate_structure = pred['verbs'][0]['description']\n",
    "        \n",
    "    return predicate_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9c5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_arg0_people(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    # people should be recognized as arg1\n",
    "\n",
    "    people = set([meta['first_name']])\n",
    "    arg_0 = get_arg(pred, arg_target='ARG0')\n",
    "\n",
    "    if arg_0 == people:\n",
    "        pass_ = True\n",
    "    else:\n",
    "        pass_ = False\n",
    "    return pass_\n",
    "\n",
    "\n",
    "expect_arg0 = Expect.single(found_arg0_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc0e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Editor()\n",
    "\n",
    "# create examples\n",
    "t = editor.template('{first_name} drove John to school.', meta=True, nsamples=1000, remove_duplicates = True)\n",
    "\n",
    "#print(type(t))\n",
    "\n",
    "# for k, v in t.items():\n",
    "#     print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe7071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dataset_BiLSTM/Active.txt', 'w') as f:\n",
    "    print(t.data, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3005bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n",
      "Test cases:      1000\n",
      "Fails (rate):    9 (0.9%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-MNR: Kathy] [V: drove] [ARG1: John] [ARG2: to school] .\n",
      "----\n",
      "[ARGM-MNR: Kathy] [V: drove] [ARG1: John] [ARG2: to school] .\n",
      "----\n",
      "[ARGM-MNR: Kathy] [V: drove] [ARG1: John] [ARG2: to school] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# initialize a rest object\n",
    "test = MFT(**t, name = 'detect_arg0_name_default_position', expect=expect_arg0)\n",
    "output = test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)\n",
    "i = test.results['preds']\n",
    "expect_for_i = test.results['expect_results']\n",
    "with open ('Output_BiLSTM/Active.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for result, exp in zip(i, expect_for_i):\n",
    "        \n",
    "        case = result['words']\n",
    "        exp = exp\n",
    "        writer.writerow([case, exp])\n",
    "        #print(case,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d30d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following piece of code was adapted from https://howtodoinjava.com/examples/python-print-to-file/\n",
    "import sys\n",
    " \n",
    "original_stdout = sys.stdout  \n",
    " \n",
    "with open('Predictions_BiLSTM/false_sentences_Active.txt', 'a') as f:\n",
    "    sys.stdout = f \n",
    "    print(test.summary(format_example_fn=format_srl), file = f)\n",
    "    # Reset the standard output\n",
    "    sys.stdout = original_stdout "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068b7f5",
   "metadata": {},
   "source": [
    "## PASSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecca62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_srl(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    return pred['verbs'][1]['description'] #second verb in this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70894ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg(pred, arg_target='ARG1'):\n",
    "    predicate_arguments = pred['verbs'][1]\n",
    "    #print(predicate_arguments)\n",
    "    words = pred['words']\n",
    "    tags = predicate_arguments['tags']\n",
    "    \n",
    "    arg_list = []\n",
    "    for t, w in zip(tags, words):\n",
    "        arg = t\n",
    "        if '-' in t:\n",
    "            arg = t.split('-')[1]\n",
    "        if arg == arg_target:\n",
    "            arg_list.append(w)\n",
    "    arg_set = set(arg_list)\n",
    "    return arg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07134e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_srl(x, pred, conf, label=None, meta=None):\n",
    "    results = []\n",
    "    predicate_structure = pred['verbs'][1]['description'] #second verb \n",
    "        \n",
    "    return predicate_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85c6fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_arg1_people(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    # people should be recognized as arg1\n",
    "\n",
    "    people = set([meta['first_name']])\n",
    "    arg_1 = get_arg(pred, arg_target='ARG1')\n",
    "\n",
    "    if arg_1 == people:\n",
    "        pass_ = True\n",
    "    else:\n",
    "        pass_ = False\n",
    "    return pass_\n",
    "\n",
    "\n",
    "expect_arg1 = Expect.single(found_arg1_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33eb6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Editor()\n",
    "\n",
    "# create examples\n",
    "t = editor.template('{first_name} got driven to school by John.', meta=True, nsamples=1000, remove_duplicates = True)\n",
    "\n",
    "#print(type(t))\n",
    "\n",
    "# for k, v in t.items():\n",
    "#     print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc317b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dataset_BiLSTM/Passive.txt', 'w') as f:\n",
    "    print(t.data, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78440fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n",
      "Test cases:      1000\n",
      "Fails (rate):    117 (11.7%)\n",
      "\n",
      "Example fails:\n",
      "Charlotte got [V: driven] [ARG2: to school] [ARG0: by John] .\n",
      "----\n",
      "Diane got [V: driven] [ARG2: to school] [ARG0: by John] .\n",
      "----\n",
      "Andrea got [V: driven] [ARG2: to school] [ARG0: by John] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# initialize a rest object\n",
    "test = MFT(**t, name = 'detect_arg1_name_default_position', expect=expect_arg1)\n",
    "output = test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)\n",
    "i = test.results['preds']\n",
    "expect_for_i = test.results['expect_results']\n",
    "with open ('Output_BiLSTM/Passive.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for result, exp in zip(i, expect_for_i):\n",
    "        \n",
    "        case = result['words']\n",
    "        exp = exp\n",
    "        writer.writerow([case, exp])\n",
    "        #print(case,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9979a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following piece of code was adapted from https://howtodoinjava.com/examples/python-print-to-file/\n",
    "import sys\n",
    " \n",
    "original_stdout = sys.stdout  \n",
    " \n",
    "with open('Predictions_BiLSTM/false_sentences_Passive.txt', 'a') as f:\n",
    "    sys.stdout = f \n",
    "    print(test.summary(format_example_fn=format_srl), file = f)\n",
    "    # Reset the standard output\n",
    "    sys.stdout = original_stdout "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
